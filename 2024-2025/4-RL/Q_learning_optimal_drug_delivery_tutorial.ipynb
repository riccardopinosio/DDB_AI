{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e40675db",
   "metadata": {},
   "source": [
    "# Q-learning Tutorial for Optimal Drug Delivery in Diabetes Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb6e03c",
   "metadata": {},
   "source": [
    "In this tutorial, we'll walk through a simple reinforcement learning scenario: a **drug delivery system** for managing a diabetic patient's blood glucose levels. <br>\n",
    "Using **Q-learning**, we'll train an agent to learn the optimal insulin dosage. This tutorial will cover:\n",
    "- Defining the MDP components (states, actions, rewards)\n",
    "- Implementing exploration with the Œµ-greedy method\n",
    "- Updating Q-values and deriving the optimal policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b8cceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45f6969",
   "metadata": {},
   "source": [
    "## Step 1: Define the MDP Components\n",
    "\n",
    "We define the states, actions, and rewards for our drug delivery problem.\n",
    "\n",
    "- **States**: Represent the patient's blood glucose levels (e.g., \"Low\", \"Normal\", \"High\").\n",
    "- **Actions**: Insulin dosages (e.g., No Insulin, Low Dose, High Dose).\n",
    "- **Rewards**: Higher rewards for maintaining blood glucose in the \"Normal\" range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b50ac9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States (Blood Glucose Levels): ['Low', 'Normal', 'High']\n",
      "Actions (Insulin Dosage Options): ['No Insulin', 'Low Dose', 'High Dose']\n",
      "\n",
      "Initial Q-Table:\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Define states representing blood glucose levels\n",
    "states = ['Low', 'Normal', 'High']\n",
    "\n",
    "# Define actions (amounts of insulin to deliver)\n",
    "actions = ['No Insulin', 'Low Dose', 'High Dose']\n",
    "\n",
    "# Initialize a Q-table with all zero values\n",
    "q_table = np.zeros((len(states), len(actions)))\n",
    "\n",
    "# Define rewards (encouraging normal glucose levels)\n",
    "rewards = {\n",
    "    'Low': -10,       # Hypoglycemia penalty\n",
    "    'Normal': 10,     # Ideal glucose level reward\n",
    "    'High': -5        # Hyperglycemia penalty\n",
    "}\n",
    "\n",
    "# Print initial setup\n",
    "print('States (Blood Glucose Levels):', states)\n",
    "print('Actions (Insulin Dosage Options):', actions)\n",
    "print('\\nInitial Q-Table:')\n",
    "print(q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a759075",
   "metadata": {},
   "source": [
    "## Step 2: Define State Transitions and Rewards\n",
    "Read the definitions of the state transitions below. Do they make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2518cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition from Normal with action No Insulin -> High\n",
      "Transition from Normal with action Low Dose -> Normal\n",
      "Transition from Normal with action High Dose -> Low\n"
     ]
    }
   ],
   "source": [
    "# Define state transitions\n",
    "def transition(state, action):\n",
    "    '''\n",
    "    Parameters: \n",
    "    state: state s of the agent\n",
    "    action: action a the agent can take in state s\n",
    "    \n",
    "    Returns:\n",
    "    The transition state s' from previous state s\n",
    "    '''\n",
    "    if state == 'Low':\n",
    "        if action == 'No Insulin':\n",
    "            return 'Low'\n",
    "        elif action == 'Low Dose':\n",
    "            return 'Normal'\n",
    "        else:\n",
    "            return 'High'\n",
    "    elif state == 'Normal':\n",
    "        if action == 'No Insulin':\n",
    "            return 'High'\n",
    "        elif action == 'Low Dose':\n",
    "            return 'Normal'\n",
    "        else:\n",
    "            return 'Low'\n",
    "    else:  # High\n",
    "        if action == 'No Insulin':\n",
    "            return 'High'\n",
    "        elif action == 'Low Dose':\n",
    "            return 'Normal'\n",
    "        else:\n",
    "            return 'Low'\n",
    "\n",
    "# Check transitions with print statements\n",
    "current_state = 'Normal'\n",
    "for action in actions:\n",
    "    next_state = transition(current_state, action)\n",
    "    print(f'Transition from {current_state} with action {action} -> {next_state}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcea6bf",
   "metadata": {},
   "source": [
    "## Step 3: Implement Q-learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caad537b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 1 - Starting state: Normal\n",
      "  Step 1: State=Normal, Action=No Insulin, Reward=-5, Next State=High\n",
      "    Old Q-value: 0.00, New Q-value: -0.50\n",
      "  Step 2: State=High, Action=No Insulin, Reward=-5, Next State=High\n",
      "    Old Q-value: 0.00, New Q-value: -0.50\n",
      "  Step 3: State=High, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 0.00, New Q-value: 1.00\n",
      "  Step 4: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 0.00, New Q-value: 1.00\n",
      "  Step 5: State=Normal, Action=High Dose, Reward=-10, Next State=Low\n",
      "    Old Q-value: 0.00, New Q-value: -1.00\n",
      "  Step 6: State=Low, Action=No Insulin, Reward=-10, Next State=Low\n",
      "    Old Q-value: 0.00, New Q-value: -1.00\n",
      "  Step 7: State=Low, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 0.00, New Q-value: 1.09\n",
      "  Step 8: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 1.00, New Q-value: 1.99\n",
      "  Step 9: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 1.99, New Q-value: 2.97\n",
      "  Step 10: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 2.97, New Q-value: 3.94\n",
      "\n",
      "Episode 2 - Starting state: Normal\n",
      "  Step 1: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 3.94, New Q-value: 4.90\n",
      "  Step 2: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 4.90, New Q-value: 5.85\n",
      "  Step 3: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 5.85, New Q-value: 6.79\n",
      "  Step 4: State=Normal, Action=High Dose, Reward=-10, Next State=Low\n",
      "    Old Q-value: -1.00, New Q-value: -1.80\n",
      "  Step 5: State=Low, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 1.09, New Q-value: 2.59\n",
      "  Step 6: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 6.79, New Q-value: 7.73\n",
      "  Step 7: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 7.73, New Q-value: 8.65\n",
      "  Step 8: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 8.65, New Q-value: 9.56\n",
      "  Step 9: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 9.56, New Q-value: 10.47\n",
      "  Step 10: State=Normal, Action=No Insulin, Reward=-5, Next State=High\n",
      "    Old Q-value: -0.50, New Q-value: -0.86\n",
      "\n",
      "Episode 3 - Starting state: Normal\n",
      "  Step 1: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 10.47, New Q-value: 11.36\n",
      "  Step 2: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 11.36, New Q-value: 12.25\n",
      "  Step 3: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 12.25, New Q-value: 13.13\n",
      "  Step 4: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 13.13, New Q-value: 13.99\n",
      "  Step 5: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 13.99, New Q-value: 14.85\n",
      "  Step 6: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 14.85, New Q-value: 15.71\n",
      "  Step 7: State=Normal, Action=No Insulin, Reward=-5, Next State=High\n",
      "    Old Q-value: -0.86, New Q-value: -1.18\n",
      "  Step 8: State=High, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 1.00, New Q-value: 3.31\n",
      "  Step 9: State=Normal, Action=No Insulin, Reward=-5, Next State=High\n",
      "    Old Q-value: -1.18, New Q-value: -1.27\n",
      "  Step 10: State=High, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 3.31, New Q-value: 5.40\n",
      "\n",
      "Episode 4 - Starting state: Low\n",
      "  Step 1: State=Low, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 2.59, New Q-value: 4.75\n",
      "  Step 2: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 15.71, New Q-value: 16.55\n",
      "  Step 3: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 16.55, New Q-value: 17.38\n",
      "  Step 4: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 17.38, New Q-value: 18.21\n",
      "  Step 5: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 18.21, New Q-value: 19.03\n",
      "  Step 6: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 19.03, New Q-value: 19.84\n",
      "  Step 7: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 19.84, New Q-value: 20.64\n",
      "  Step 8: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 20.64, New Q-value: 21.43\n",
      "  Step 9: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 21.43, New Q-value: 22.22\n",
      "  Step 10: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 22.22, New Q-value: 23.00\n",
      "\n",
      "Episode 5 - Starting state: Low\n",
      "  Step 1: State=Low, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 4.75, New Q-value: 7.34\n",
      "  Step 2: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 23.00, New Q-value: 23.77\n",
      "  Step 3: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 23.77, New Q-value: 24.53\n",
      "  Step 4: State=Normal, Action=High Dose, Reward=-10, Next State=Low\n",
      "    Old Q-value: -1.80, New Q-value: -1.96\n",
      "  Step 5: State=Low, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 7.34, New Q-value: 9.81\n",
      "  Step 6: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 24.53, New Q-value: 25.28\n",
      "  Step 7: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 25.28, New Q-value: 26.03\n",
      "  Step 8: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 26.03, New Q-value: 26.77\n",
      "  Step 9: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 26.77, New Q-value: 27.50\n",
      "  Step 10: State=Normal, Action=Low Dose, Reward=10, Next State=Normal\n",
      "    Old Q-value: 27.50, New Q-value: 28.23\n",
      "\n",
      "Final Q-Table after training:\n",
      "[[-1.          9.81498931  0.        ]\n",
      " [-1.26738399 28.22694674 -1.96096371]\n",
      " [-0.5         5.39567139  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Q-learning parameters\n",
    "alpha = 0.1      # Learning rate\n",
    "gamma = 0.9      # Discount factor\n",
    "epsilon = 0.2    # Initial exploration rate\n",
    "\n",
    "# Helper function to get action based on Œµ-greedy strategy\n",
    "def choose_action(state_index):\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        return random.choice(range(len(actions)))  # Explore\n",
    "    else:\n",
    "        return np.argmax(q_table[state_index])     # Exploit\n",
    "\n",
    "# Q-learning function\n",
    "def q_learning(episodes=100):\n",
    "    global epsilon   # Why did we define a global epsilon?\n",
    "    for episode in range(episodes):\n",
    "        state = random.choice(states)\n",
    "        print(f'\\nEpisode {episode+1} - Starting state: {state}')\n",
    "\n",
    "        for step in range(10):  # Assume 10 steps per episode\n",
    "            state_index = states.index(state)\n",
    "            action_index = choose_action(state_index)\n",
    "            action = actions[action_index]\n",
    "\n",
    "            # Observe the next state and reward\n",
    "            next_state = transition(state, action)\n",
    "            reward = rewards[next_state]\n",
    "            next_state_index = states.index(next_state)\n",
    "\n",
    "            # Q-learning update\n",
    "            old_value = q_table[state_index, action_index]\n",
    "            next_max = np.max(q_table[next_state_index])\n",
    "            q_table[state_index, action_index] = old_value + alpha * (reward + gamma * next_max - old_value)\n",
    "\n",
    "            # Print details of the Q-update step\n",
    "            print(f'  Step {step+1}: State={state}, Action={action}, Reward={reward}, Next State={next_state}')\n",
    "            print(f'    Old Q-value: {old_value:.2f}, New Q-value: {q_table[state_index, action_index]:.2f}')\n",
    "\n",
    "            # Update state and gradually reduce exploration rate\n",
    "            state = next_state\n",
    "            epsilon = max(epsilon * 0.99, 0.01)\n",
    "\n",
    "# Run Q-learning with print statements to trace updates\n",
    "q_learning(episodes=5)\n",
    "print('\\nFinal Q-Table after training:')\n",
    "print(q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeb6381",
   "metadata": {},
   "source": [
    "### Answer the following questions on Step 3:\n",
    "- In the code above what is the variable *\"episode\"*? HINT: Look for episodic tasks in reinforcement learning!\n",
    "- What is training here? Can you connect the Q-learning update from the lecture? \n",
    "- What stopping criterion has been used here to check if the Q-values have stabilized?\n",
    "- Why a \"global epsilon\" is used in the code above? \n",
    "- Are there any hyper-parameters in this model? Is it possible to do hyperparameter tuning here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1b1b5c",
   "metadata": {},
   "source": [
    "## Step 4: Extract Optimal Policy and Interpret Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "211edb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal Policy Derived from Q-Table:\n",
      "  In state Low, the best action is: Low Dose\n",
      "  In state Normal, the best action is: Low Dose\n",
      "  In state High, the best action is: Low Dose\n"
     ]
    }
   ],
   "source": [
    "# Derive the optimal policy from the Q-table\n",
    "optimal_policy = {}\n",
    "for state in states:\n",
    "    state_index = states.index(state)\n",
    "    best_action_index = np.argmax(q_table[state_index])\n",
    "    optimal_policy[state] = actions[best_action_index]\n",
    "\n",
    "# Print optimal policy for students to see the results\n",
    "print('\\nOptimal Policy Derived from Q-Table:')\n",
    "for state, action in optimal_policy.items():\n",
    "    print(f'  In state {state}, the best action is: {action}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ef0c0c",
   "metadata": {},
   "source": [
    "### Answer the following questions on Step 4:\n",
    "- In the code above can you figure out how the optimal policy is calculate for every state from the following definition we saw in the lecture: <br>\n",
    "$$\n",
    "\\begin{aligned}\n",
    "ùúã^{‚àó}(ùë†)=\\underset{a}{\\operatorname{\\argmax}} ùëÑ(ùë†,ùëé)\n",
    "\\end{aligned}\n",
    "$$\n",
    "- Do you agree with the optimal policy calculated from the Q-table? What do the Q-values represent?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
